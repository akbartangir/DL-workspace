{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rock-Paper-Scissors Classification with Convolutional Neural Networks (CNN)**\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will build a Convolutional Neural Network (CNN) to classify images of hand gestures: Rock, Paper, and Scissors. The process will include:\n",
    "\n",
    "1. **Importing Libraries**\n",
    "2. **Data Loading and Preparation**\n",
    "3. **Model Building**\n",
    "4. **Model Training**\n",
    "5. **Model Evaluation**\n",
    "6. **Making Predictions on New Images**\n",
    "\n",
    "We will use TensorFlow and Keras for building the model and work through each step with detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importing Necessary Libraries**\n",
    "\n",
    "We start by importing essential libraries:\n",
    "\n",
    "- **TensorFlow**: Main library for building and training the CNN.\n",
    "- **TensorFlow Datasets**: For loading the Rock-Paper-Scissors dataset.\n",
    "- **NumPy**: For numerical operations.\n",
    "- **Matplotlib.pyplot**: For data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Loading and Preparing the Dataset**\n",
    "\n",
    "We will load the Rock-Paper-Scissors dataset from TensorFlow Datasets and preprocess it by:\n",
    "\n",
    "- **Resizing Images**: Standardizing image sizes.\n",
    "- **Normalizing Pixel Values**: Scaling pixel values to the range [0, 1].\n",
    "- **Data Augmentation**: Enhancing the dataset with transformed images to improve model generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_images(folder_path, target_size):\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         for name in files:\n",
    "#             if name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "#                 img_path = os.path.join(root, name)\n",
    "#                 img = Image.open(img_path)\n",
    "#                 img = img.resize(target_size)\n",
    "#                 img.save(img_path)\n",
    "\n",
    "# resize_images('dataset/train', (150, 150))\n",
    "# resize_images('dataset/test', (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import tensorflow_datasets as tfds\n",
    "# # import tensorflow as tf\n",
    "# # import os\n",
    "# # import numpy as np\n",
    "# # from PIL import Image\n",
    "\n",
    "# def download_and_prepare_tfds_rps():\n",
    "#     \"\"\"Download RPS dataset from TensorFlow Datasets\"\"\"\n",
    "#     # Load the dataset\n",
    "#     dataset, info = tfds.load('rock_paper_scissors', \n",
    "#                             split=['train', 'test'],\n",
    "#                             with_info=True,\n",
    "#                             as_supervised=True)\n",
    "    \n",
    "#     train_ds, test_ds = dataset\n",
    "#     return train_ds, test_ds\n",
    "\n",
    "# def save_tfds_images(dataset, output_path, split='train'):\n",
    "#     \"\"\"Save TensorFlow dataset images to disk\"\"\"\n",
    "#     if not os.path.exists(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "        \n",
    "#     for image, label in dataset:\n",
    "#         # Convert tensor to numpy array\n",
    "#         image_array = image.numpy()\n",
    "        \n",
    "#         # Get class name based on label\n",
    "#         class_names = ['rock', 'paper', 'scissors']\n",
    "#         class_name = class_names[label]\n",
    "        \n",
    "#         # Create class directory if it doesn't exist\n",
    "#         class_dir = os.path.join(output_path, split, class_name)\n",
    "#         if not os.path.exists(class_dir):\n",
    "#             os.makedirs(class_dir)\n",
    "            \n",
    "#         # Generate unique filename\n",
    "#         filename = f\"tfds_{split}_{class_name}_{len(os.listdir(class_dir))}.jpg\"\n",
    "        \n",
    "#         # Resize image to match your current dataset size\n",
    "#         image_pil = Image.fromarray(image_array)\n",
    "#         image_pil = image_pil.resize((150, 150))\n",
    "        \n",
    "#         # Save image\n",
    "#         image_pil.save(os.path.join(class_dir, filename))\n",
    "\n",
    "# # Download and prepare TFDS dataset\n",
    "# train_ds, test_ds = download_and_prepare_tfds_rps()\n",
    "\n",
    "# # Save images to your dataset directory\n",
    "# save_tfds_images(train_ds, './dataset', 'train')\n",
    "# save_tfds_images(test_ds, './dataset', 'test')\n",
    "\n",
    "# print(\"Dataset combination complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Load datasets using tf.keras.utils.image_dataset_from_directory\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/test',\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Define augmentation functions\n",
    "def augment(image, label):\n",
    "    # Random brightness\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    \n",
    "    # Random contrast\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    \n",
    "    # Random flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "    # Random rotation\n",
    "    # image = tf.image.rot90(\n",
    "    #     image,\n",
    "    #     tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    # )\n",
    "    \n",
    "    # Ensure pixel values are in [0,1]\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Configure datasets for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.shuffle(1000)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "# Normalize validation and test sets\n",
    "val_ds = val_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "val_ds = val_ds.cache()\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**\n",
    "\n",
    "Let's visualize a few samples from the training dataset to understand what the images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['paper', 'rock', 'scissors']\n",
    "# class_names = train_ds.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(6):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Building the CNN Model**\n",
    "\n",
    "We will build a Sequential CNN model consisting of:\n",
    "\n",
    "- **Convolutional Layers**: To extract features from images.\n",
    "- **Pooling Layers**: To reduce spatial dimensions.\n",
    "- **Flatten Layer**: To convert the 2D feature maps into 1D feature vectors.\n",
    "- **Dense Layers**: For classification based on extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (9, 9), activation='relu', input_shape=IMG_SIZE + (3,)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (9, 9), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compiling the Model**\n",
    "\n",
    "We compile the model using:\n",
    "\n",
    "- **Loss Function**: `sparse_categorical_crossentropy` for multi-class classification.\n",
    "- **Optimizer**: `adam` optimizer for efficient training.\n",
    "- **Metrics**: `accuracy` to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Training the Model**\n",
    "\n",
    "We train the model using the training dataset for a certain number of epochs.\n",
    "\n",
    "- **Epochs**: Number of times the model will cycle through the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=test_ds,\n",
    "#     epochs=10\n",
    "# )\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Evaluating the Model**\n",
    "\n",
    "After training, we evaluate the model on the test dataset to check its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Training Results**\n",
    "\n",
    "We plot the training and validation accuracy and loss to visualize the model's performance over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(5)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model-3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9. Making Predictions on New Images**\n",
    "\n",
    "We can use the trained model to predict the class of new images.\n",
    "\n",
    "- **Load and Preprocess the Image**: Resize and normalize the image.\n",
    "- **Predict**: Use `model.predict` to get the prediction probabilities.\n",
    "- **Interpret the Result**: Find the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define class names based on your dataset structure\n",
    "class_names = ['paper', 'rock', 'scissors']  # Make sure this matches your folder structure order\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"\n",
    "    Predicts and displays the image with its prediction and confidence\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    image_array = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
    "    image_array = tf.expand_dims(image_array, 0)\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(image_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_array[0])\n",
    "    plt.title(f'Prediction: {class_names[predicted_class]} ({confidence * 100:.2f}%)')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed probabilities\n",
    "    for i, prob in enumerate(predictions[0]):\n",
    "        print(f'{class_names[i]}: {prob*100:.2f}%')\n",
    "\n",
    "def predict_image_simple(image_path):\n",
    "    \"\"\"\n",
    "    Simpler version that just prints the prediction\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    \n",
    "    print(f'Predicted class: {class_names[predicted_class]} (Confidence: {confidence*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Model with a New Image**\n",
    "\n",
    "Let's test the model with a new image of a hand gesture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to your image\n",
    "image_path = './test-examples/scissors2.jpg'\n",
    "predict_image(image_path)\n",
    "\n",
    "# predict_image_simple(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
